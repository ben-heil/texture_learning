{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, models\n",
    "from torch.utils import data\n",
    "import torch\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from skimage.io import imread\n",
    "from numpy.random import poisson, normal, beta, choice\n",
    "import time\n",
    "from copy import deepcopy, copy\n",
    "from PIL import Image\n",
    "import bagnets.pytorchnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "np.random.seed(seed)                                                                       \n",
    "torch.manual_seed(seed) \n",
    "\n",
    "img_transform = transforms.Compose([transforms.Resize(255),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])]\n",
    "                                   )\n",
    "dataset = ImageFolder(root='/Users/jlakkis/Downloads/plant-seedlings-classification/train', transform=img_transform)\n",
    "\n",
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " This is a function that takes in an image, and a dispersion parameter\n",
    " p and n define the size of the mean pixel patch and the number of patches\n",
    " replaces pixel with random noise in randomly selected patches of the image\n",
    "\"\"\"\n",
    "\n",
    "def patchnoiser(image, theta, p , n):\n",
    "    x, y, c = image.shape\n",
    "    means = torch.sum(image, dim=(0,1))/x/y\n",
    "    \n",
    "    for i in range(n):\n",
    "        px = min(poisson(lam = p, size=None),x)\n",
    "        py = min(poisson(lam = p, size=None),y)\n",
    "        \n",
    "        max_x = x + 1 - px\n",
    "        max_y = y + 1 - py\n",
    "        \n",
    "        x_range = list(range(max_x))\n",
    "        y_range = list(range(max_y))\n",
    "        \n",
    "        patch1_x = choice(x_range)\n",
    "        patch1_y = choice(y_range)\n",
    "        \n",
    "        def pixeltonoise(x):\n",
    "            if(x<10 **(-6)):\n",
    "                return x\n",
    "            if(x > 1 - 10**(-6)):\n",
    "                return x\n",
    "\n",
    "            a = (1 - theta)/theta * x\n",
    "            b = (1 - theta)/theta * (1 - x)\n",
    "\n",
    "            return(beta(a, b))\n",
    "    \n",
    "        pixeltonoise = np.vectorize(pixeltonoise)\n",
    "        \n",
    "        noise0 = pixeltonoise(float(means[0]) * np.ones(shape = (px, py)) )\n",
    "        noise1 = pixeltonoise(float(means[1]) * np.ones(shape = (px, py)) )\n",
    "        noise2 = pixeltonoise(float(means[2]) * np.ones(shape = (px, py)) )\n",
    "        \n",
    "        noise0 = torch.from_numpy(noise0)\n",
    "        noise1 = torch.from_numpy(noise1)\n",
    "        noise2 = torch.from_numpy(noise2)\n",
    "        \n",
    "        image[patch1_x:(patch1_x+px), patch1_y:(patch1_y+py),0] = noise0\n",
    "        image[patch1_x:(patch1_x+px), patch1_y:(patch1_y+py),1] = noise1\n",
    "        image[patch1_x:(patch1_x+px), patch1_y:(patch1_y+py),2] = noise2\n",
    "    \n",
    "    return(image)\n",
    "\n",
    "\"\"\"\n",
    " This is a function that takes in an image, and a dispersion parameter\n",
    " replaces each pixel with a noisy version of that pixel \n",
    "\"\"\"\n",
    "\n",
    "def uniformnoiser(image, theta):\n",
    "    x, y, c = image.shape\n",
    "    \n",
    "    def pixeltonoise(x):\n",
    "        if(x<10 **(-6)):\n",
    "            return x\n",
    "        if(x > 1 - 10**(-6)):\n",
    "            return x\n",
    "        \n",
    "        a = (1 - theta)/theta * x\n",
    "        b = (1 - theta)/theta * (1 - x)\n",
    "        \n",
    "        return(beta(a, b))\n",
    "    \n",
    "    pixeltonoise = np.vectorize(pixeltonoise)\n",
    "    \n",
    "    image = np.asarray(image)\n",
    "    image = pixeltonoise(image)\n",
    "    image = torch.from_numpy(image)\n",
    "    \n",
    "    return(image)\n",
    "\n",
    "\"\"\"\n",
    " This is a function that takes in an image, and a dispersion parameter\n",
    " p and n define the size of the mean pixel patch and the number of patches\n",
    " replaces pixel with random noise in randomly selected patches of the image\n",
    "\"\"\"\n",
    "\n",
    "def patchswap(image, p, n):\n",
    "    x, y, c = image.shape\n",
    "    \n",
    "    for i in range(n):\n",
    "        px = min(poisson(lam = p, size=None),x)\n",
    "        py = min(poisson(lam = p, size=None),y)\n",
    "        \n",
    "        max_x = x + 1 - px\n",
    "        max_y = y + 1 - py\n",
    "        \n",
    "        x_range = list(range(max_x))\n",
    "        y_range = list(range(max_y))\n",
    "        \n",
    "        patch1_x = choice(x_range)\n",
    "        patch1_y = choice(y_range)\n",
    "        patch1 = deepcopy(image[patch1_x:(patch1_x + px),patch1_y:(patch1_y + py),0:3])\n",
    "\n",
    "        patch2_x = choice(x_range)\n",
    "        patch2_y = choice(y_range)\n",
    "        patch2 = deepcopy(image[patch2_x:(patch2_x + px),patch2_y:(patch2_y + py),0:3])\n",
    "        \n",
    "        image[patch1_x:(patch1_x + px),patch1_y:(patch1_y + py),0:3] = patch2\n",
    "        image[patch2_x:(patch2_x + px),patch2_y:(patch2_y + py),0:3] = patch1\n",
    "    \n",
    "    return(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A pytorch dataset class that retrieves and modifies images in real time\"\"\"\n",
    "\"\"\"\n",
    "    Corruption Modes:\n",
    "        1. None: return clean resized image\n",
    "        2. patchswap: swap patches of pixels\n",
    "        3. noiseypatch: Randomly select patches of pixels and replace them with randomly distributed noise\n",
    "        4. uniformnoise: For each pixel, replace that pixel's color values with noisy versions of that \n",
    "            pixel's color values\n",
    "\"\"\"\n",
    "class tgenerator(data.Dataset):\n",
    "\n",
    "    def __init__(self, IDlink):\n",
    "        'Initialization'\n",
    "        self.link = IDlink\n",
    "        self.list_IDs = listdir(IDlink)\n",
    "        self.mode = 'None'\n",
    "        self.imageview = True\n",
    "        self.transformer = transforms.Compose([transforms.Resize(255),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])])\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def viewmode(self):\n",
    "        '''Switch the shaping of the tensors. For CNN models, call this method in order\n",
    "        to ensure that the first dimension of the image tensor is the channel'''\n",
    "        self.imageview = not self.imageview\n",
    "    \n",
    "    def setmode_none(self):\n",
    "        self.mode = 'none'\n",
    "    \n",
    "    def setmode_patchswap(self,p = 1, n = 0):\n",
    "        self.mode = 'patchswap'\n",
    "        self.p = p\n",
    "        self.n = n\n",
    "        \n",
    "    def setmode_noiseypatch(self, theta = 1/4, p = 1, n = 0):\n",
    "        self.mode = 'noiseypatch'\n",
    "        self.theta = theta\n",
    "        self.p = p\n",
    "        self.n = n\n",
    "        \n",
    "    def setmode_uniformnoise(self, theta = 1/4):\n",
    "        self.mode = 'uniformnoise'\n",
    "        self.theta = theta\n",
    "        \n",
    "    def setparams(self, resize=255, centercrop=224):\n",
    "        self.size = size\n",
    "        self.transformer = transforms.Compose([transforms.Resize(resize),\n",
    "                                    transforms.CenterCrop(centercrop),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])]\n",
    "        )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.link + '/' + ID)\n",
    "        X = self.transformer(X)\n",
    "        X = X.permute(1,2,0)\n",
    "        \n",
    "        if(self.mode == 'patchswap'):\n",
    "            X = patchswap(X, self.p, self.n)\n",
    "            \n",
    "        if(self.mode == 'noiseypatch'):\n",
    "            X = patchnoiser(X, self.theta, self.p, self.n)\n",
    "            \n",
    "        if(self.mode == 'uniformnoise'):\n",
    "            X = uniformnoiser(X, self.theta)\n",
    "\n",
    "        if(not self.imageview):\n",
    "            X = X.permute(2,0,1)\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BagNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"/Users/jlakkis/Downloads/trained_bagnet.pkl\"\n",
    "bagnet = bagnets.pytorchnet.bagnet17(pretrained=False, num_classes = 12)\n",
    "bagnet.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))\n",
    "bagnet.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(range(794))\n",
    "columns=['file','species']\n",
    "df_ = pd.DataFrame(index = index, columns=columns)\n",
    "df_ = df_.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"/Users/jlakkis/Desktop/Temporary Files/CIS 520 Project/data/test\"\n",
    "testset = tgenerator(link)\n",
    "testset.viewmode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on clean test set.\n",
    "\n",
    "Kaggle F1 Score: 0.72040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlakkis/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/jlakkis/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "for i in range(794):\n",
    "    im = testset[i]\n",
    "    im = im.view(1,3,224,224)\n",
    "    \n",
    "    ytest = torch.max(bagnet(im),1)[1][0].detach()\n",
    "    \n",
    "    if(i % 100 ==0):\n",
    "        print(i)\n",
    "    \n",
    "    df_['file'][i] = testset.list_IDs[i]\n",
    "    df_['species'][i] = dataset.classes[int(ytest)]\n",
    "    \n",
    "df_.to_csv(path_or_buf = \"/Users/jlakkis/Desktop/predictions_bagnet.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on uniform noise perturbed test set.\n",
    "\n",
    "Kaggle F1 Score: 0.11335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "testset.setmode_uniformnoise(theta=0.6)\n",
    "\n",
    "for i in range(794):\n",
    "    im = testset[i]\n",
    "    im = im.view(1,3,224,224)\n",
    "    \n",
    "    ytest = torch.max(bagnet(im.float()),1)[1][0].detach()\n",
    "    \n",
    "    if(i % 100 ==0):\n",
    "        print(i)\n",
    "    \n",
    "    df_['file'][i] = testset.list_IDs[i]\n",
    "    df_['species'][i] = dataset.classes[int(ytest)]\n",
    "    \n",
    "df_.to_csv(path_or_buf = \"/Users/jlakkis/Desktop/predictions_unformnoise_bagnet.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on noisy patch perturbed test set.\n",
    "\n",
    "Kaggle F1 Score: 0.20025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "testset.setmode_noiseypatch(theta=0.1,p=30,n=40)\n",
    "\n",
    "for i in range(794):\n",
    "    im = testset[i]\n",
    "    im = im.view(1,3,224,224)\n",
    "    \n",
    "    ytest = torch.max(bagnet(im.float()),1)[1][0].detach()\n",
    "    \n",
    "    if(i % 100 ==0):\n",
    "        print(i)\n",
    "    \n",
    "    df_['file'][i] = testset.list_IDs[i]\n",
    "    df_['species'][i] = dataset.classes[int(ytest)]\n",
    "    \n",
    "df_.to_csv(path_or_buf = \"/Users/jlakkis/Desktop/predictions_noiseypatch_bagnet.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on patchswap perturbed test set.\n",
    "\n",
    "Kaggle F1 Score: 0.52267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "testset.setmode_patchswap(p=20, n=50)\n",
    "\n",
    "for i in range(794):\n",
    "    im = testset[i]\n",
    "    im = im.view(1,3,224,224)\n",
    "    \n",
    "    ytest = torch.max(bagnet(im.float()),1)[1][0].detach()\n",
    "    \n",
    "    if(i % 100 ==0):\n",
    "        print(i)\n",
    "    \n",
    "    df_['file'][i] = testset.list_IDs[i]\n",
    "    df_['species'][i] = dataset.classes[int(ytest)]\n",
    "    \n",
    "df_.to_csv(path_or_buf = \"/Users/jlakkis/Desktop/predictions_patchswap_bagnet.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on texturized test set.\n",
    "\n",
    "Kaggle F1 Score: 0.19269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "link = \"/Users/jlakkis/Desktop/Temporary Files/CIS 520 Project/data/texturized\"\n",
    "testset = tgenerator(link)\n",
    "testset.viewmode()\n",
    "\n",
    "for i in range(794):\n",
    "    im = testset[i]\n",
    "    im = im.view(1,3,224,224)\n",
    "    \n",
    "    ytest = torch.max(bagnet(im.float()),1)[1][0].detach()\n",
    "    \n",
    "    if(i % 100 ==0):\n",
    "        print(i)\n",
    "    \n",
    "    df_['file'][i] = testset.list_IDs[i]\n",
    "    df_['species'][i] = dataset.classes[int(ytest)]\n",
    "    \n",
    "df_.to_csv(path_or_buf = \"/Users/jlakkis/Desktop/predictions_texturized_bagnet.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
